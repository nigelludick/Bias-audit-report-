# Bias-audit-report-
# ğŸ¤– AI RÃ©sumÃ© Screener Bias Audit  

![Python](https://img.shields.io/badge/Python-3.10%2B-blue?logo=python)
![Fairlearn](https://img.shields.io/badge/Fairlearn-Fairness%20Audit-brightgreen?logo=python)
![scikit-learn](https://img.shields.io/badge/scikit--learn-Model%20Training-orange?logo=scikit-learn)
![License: MIT](https://img.shields.io/badge/License-MIT-yellow)
![Status](https://img.shields.io/badge/Status-Completed-success)
![Report](https://img.shields.io/badge/Output-PDF%20%26%20PPTX-lightgrey)

---

## ğŸ§  Overview
This project investigates potential **bias and fairness issues** in an **AI rÃ©sumÃ© screening model**.  
It evaluates model performance and fairness across demographic groups using synthetic data, and applies mitigation strategies to improve equity in automated hiring.

The audit demonstrates how responsible AI practices can make recruitment systems **fairer, explainable, and transparent**.

---

## âš™ï¸ Key Features
- ğŸ§© **Synthetic Data Generation:** Automatically creates realistic rÃ©sumÃ©-style candidate data (skills, education, experience, gender, and age group).  
- âš–ï¸ **Bias Detection:** Evaluates fairness metrics such as *Demographic Parity Difference (DPD)* using the **Fairlearn** library.  
- ğŸª„ **Bias Mitigation:** Applies *Exponentiated Gradient Reduction* with *Demographic Parity* constraints to reduce unfairness.  
- ğŸ“Š **Visualization:** Generates professional plots for data distributions, selection rates, and performance metrics.  
- ğŸ“„ **Automated Report:** Exports a full **PDF bias audit report** with charts, metrics, and a professional summary.  
- ğŸ’¼ **Presentation Deck:** Creates a polished **PowerPoint presentation** summarizing the findings and visuals.

---

## ğŸ§° Tech Stack

| Tool | Purpose |
|------|----------|
| **Python 3.10+** | Core programming language |
| **pandas / numpy** | Data manipulation |
| **scikit-learn** | Model training and evaluation |
| **Fairlearn** | Fairness metrics and bias mitigation |
| **matplotlib / plotly** | Data visualization |
| **ReportLab / PyPDF2** | PDF generation |
| **python-pptx** | PowerPoint presentation creation |

---

## ğŸ§® How It Works
1. **Generate Data:**  
   Creates a synthetic rÃ©sumÃ© dataset with demographic and skill-based features.  
2. **Train Model:**  
   Trains a logistic regression model to predict hiring outcomes.  
3. **Run Fairness Audit:**  
   Calculates fairness metrics and evaluates demographic parity differences.  
4. **Mitigate Bias:**  
   Applies fairness constraints to improve model balance.  
5. **Visualize Results:**  
   Produces modern, professional charts and visuals.  
6. **Generate Reports:**  
   Exports an automated **PDF** and **PowerPoint** summarizing all findings.

---

## ğŸš€ Getting Started

### 1ï¸âƒ£ Clone the Repository
```bash
git clone https://github.com/<your-username>/ai-bias-audit.git
cd ai-bias-audit
Create and Activate a Virtual Environment
python -m venv .venv
.\.venv\Scripts\activate   # (Windows)
# OR
source .venv/bin/activate  # (Mac/Linux)

3ï¸âƒ£ Install Dependencies
pip install -r requirements.txt

4ï¸âƒ£ Run the Bias Audit
python bias_audit.py


ğŸ“‚ Outputs will be saved in the /outputs folder:

outputs/
â”œâ”€â”€ AI_Bias_Audit_Report.pdf
â”œâ”€â”€ AI_Bias_Audit_Presentation.pptx
â””â”€â”€ *.png  (charts and visuals)

ğŸ“ˆ Example Results
Metric	Before Mitigation	After Mitigation
Demographic Parity Difference (DPD)	0.21	0.07
Accuracy	0.83	0.81
Fairness Improvement	+65% Bias Reduction	

The results show that applying fairness constraints improved demographic parity while maintaining high accuracy â€” demonstrating the value of responsible AI.

ğŸ§© Project Structure
AI_Bias_Audit/
â”‚
â”œâ”€â”€ bias_audit.py                # Main script
â”œâ”€â”€ requirements.txt             # Dependencies
â”œâ”€â”€ README.md                    # Documentation
â””â”€â”€ outputs/                     # Generated reports & visuals

ğŸ§¾ Ethical Statement

This project supports responsible and ethical AI development.
By identifying and mitigating bias, we ensure fairness and transparency in automated decision-making â€” especially in critical use cases like hiring.

ğŸ‘¤ Author

Nigel Ludick
ğŸ’¼ AI Developer & Fairness Enthusiast
ğŸ“§ nigelludick88@gmail.com

ğŸŒ GitHub Profile

ğŸªª License

This project is licensed under the MIT License â€” free to use, modify, and share with attribution.

ğŸŒ Quote

â€œFair AI isnâ€™t just about accuracy â€” itâ€™s about trust, transparency, and accountability.â€

ğŸš€ Empowering ethical AI through fairness audits.

âš™ï¸ Setup Guide

Follow these steps to set up and run the AI RÃ©sumÃ© Screener Bias Audit project on your local machine:

# 1ï¸âƒ£ Clone the repository
git clone https://github.com/<your-username>/ai-bias-audit.git
cd ai-bias-audit

# 2ï¸âƒ£ Create and activate a virtual environment
python -m venv .venv
.\.venv\Scripts\activate   # (Windows)
# OR
source .venv/bin/activate  # (Mac/Linux)

# 3ï¸âƒ£ Install dependencies
pip install -r requirements.txt

# 4ï¸âƒ£ Run the project
python bias_audit.py


ğŸ“‚ Outputs:
All reports, visuals, and presentation files will be automatically generated inside the outputs/ folder:

outputs/
â”œâ”€â”€ AI_Bias_Audit_Report.pdf
â”œâ”€â”€ AI_Bias_Audit_Presentation.pptx
â””â”€â”€ charts/
